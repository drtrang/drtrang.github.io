{"meta":{"title":"Trang's Blog","subtitle":"闷不骚写代码","description":"后端研发一枚，喜欢造轮子，严重工具控","author":"Trang","url":"http://blog.trang.space"},"pages":[{"title":"","date":"2018-04-16T00:27:44.967Z","updated":"2017-07-14T08:29:07.371Z","comments":true,"path":"404.html","permalink":"http://blog.trang.space/404.html","excerpt":"","text":""},{"title":"主页","date":"2017-07-14T08:10:34.000Z","updated":"2017-08-17T13:58:46.508Z","comments":false,"path":"index.html","permalink":"http://blog.trang.space/index.html","excerpt":"","text":""},{"title":"关于","date":"2017-07-14T08:10:34.000Z","updated":"2018-04-28T04:50:53.620Z","comments":false,"path":"about/index.html","permalink":"http://blog.trang.space/about/index.html","excerpt":"","text":"Write the code. Change the world."},{"title":"分类","date":"2017-07-14T08:10:21.000Z","updated":"2017-07-14T08:14:06.152Z","comments":false,"path":"categories/index.html","permalink":"http://blog.trang.space/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-07-14T08:10:02.000Z","updated":"2017-07-14T08:12:38.018Z","comments":false,"path":"tags/index.html","permalink":"http://blog.trang.space/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Druid 中 SQL 格式化的 BUG","slug":"Druid 中 SQL 格式化的 BUG","date":"2018-02-25T16:00:00.000Z","updated":"2018-02-26T09:38:01.792Z","comments":true,"path":"2018/02/26/Druid 中 SQL 格式化的 BUG/","link":"","permalink":"http://blog.trang.space/2018/02/26/Druid 中 SQL 格式化的 BUG/","excerpt":"前段时间在写一个格式化 SQL 的拦截器（SqlFormatterInterceptor），其中格式化的部分借用了 Druid 现成的工具类 SQLUtils，但在使用过程中发现输出的 SQL 中会出现多余的空格，复现场景如下。","text":"前段时间在写一个格式化 SQL 的拦截器（SqlFormatterInterceptor），其中格式化的部分借用了 Druid 现成的工具类 SQLUtils，但在使用过程中发现输出的 SQL 中会出现多余的空格，复现场景如下。 原始 SQL12345String sql = \"SELECT id,task_id,task_source, housedel_code, del_type, office_address, company_code, brand, \" + \"class1_code, class2_code, class2_name, status, create_time, end_time, creator_ucid, creator_name, \" + \"org_code, prove_id, prove_time, audit_ucid, audit_name, audit_reject_reason, audit_content, \" + \"audit_time, pass_mode, sms_content, sms_time \\r\\n FROM \" + \"sh_true_house_task \\r\\n WHERE office_address = 0 AND status = 0 ORDER BY id DESC\"; 默认格式化12345678910111213// 格式化代码SQLUtils.formatMySql(sql)// 输出结果SELECT id, task_id, task_source, housedel_code, del_type , office_address, company_code, brand, class1_code, class2_code , class2_name, status, create_time, end_time, creator_ucid , creator_name, org_code, prove_id, prove_time, audit_ucid , audit_name, audit_reject_reason, audit_content, audit_time, pass_mode , sms_content, sms_timeFROM sh_true_house_taskWHERE office_address = 0 AND status = 0ORDER BY id DESC 仅大写格式化1234// 格式化代码SQLUtils.formatMySql(sql, new FormatOption(VisitorFeature.OutputUCase))// 输出结果SELECT id, task_id, task_source, housedel_code, del_type , office_address, company_code, brand, class1_code, class2_code , class2_name, status, create_time, end_time, creator_ucid , creator_name, org_code, prove_id, prove_time, audit_ucid , audit_name, audit_reject_reason, audit_content, audit_time, pass_mode , sms_content, sms_time FROM sh_true_house_task WHERE office_address = 0 AND status = 0 ORDER BY id DESC 由上述结果可以看到，在仅使用 OutputUCase 配置时，输出的 SQL 中 del_type、class2_code 等字符后有多余的空格，经过仔细的翻看源码，问题最终定位在 SQLASTOutputVisitor.java 的第 440 行。 这段代码发生在格式化的最后步骤，拼接输出 SQL 的时候，具体逻辑是分析查询的数据库列，每当 column 数量为 5 的倍数时就调用 println() 方法。12345// SQLASTOutputVisitor.java#L386if (lineItemCount &gt;= selectListNumberOfLine) &#123; lineItemCount = paramCount; println();&#125; 而 println() 的实现中，如果不开启 OutputPrettyFormat 特性，就会在当前 SQL 后增加一个空格。1234567// SQLASTOutputVisitor.java#L440public void println() &#123; if (!isPrettyFormat()) &#123; print(' '); return; &#125;&#125; 目前尚不明确这行代码的意图，但就结果来看，最终得到的 SQL 并不符合强迫症的审美 : (，该问题我已提到官方 ISSUE#2347，期待官方给出答案。","categories":[{"name":"技术内幕","slug":"技术内幕","permalink":"http://blog.trang.space/categories/技术内幕/"}],"tags":[{"name":"druid","slug":"druid","permalink":"http://blog.trang.space/tags/druid/"}]},{"title":"禁止 MyBatis 打印 SQL 的功能","slug":"禁止 MyBatis 打印 SQL 的功能","date":"2018-02-25T16:00:00.000Z","updated":"2018-02-26T09:36:25.276Z","comments":true,"path":"2018/02/26/禁止 MyBatis 打印 SQL 的功能/","link":"","permalink":"http://blog.trang.space/2018/02/26/禁止 MyBatis 打印 SQL 的功能/","excerpt":"背景昨天在整理日志的时候，打算将每次执行的 SQL 打印出来（开发环境），便于快速定位问题。 在已知的两种打印方式中，MyBatis 会将预处理 SQL、参数、返回结果分别打印，而 Druid 可以更细致的对打印内容进行自定义，并且可以直接打印可执行 SQL，于是决定使用 Druid 来打印 SQL。","text":"背景昨天在整理日志的时候，打算将每次执行的 SQL 打印出来（开发环境），便于快速定位问题。 在已知的两种打印方式中，MyBatis 会将预处理 SQL、参数、返回结果分别打印，而 Druid 可以更细致的对打印内容进行自定义，并且可以直接打印可执行 SQL，于是决定使用 Druid 来打印 SQL。 MyBatis 打印 SQL1232018-02-26 14:11:05.772 DEBUG 14164 --- [28620-thread-21] c.l.m.q.d.H.selectCustom : ==&gt; Preparing: SELECT id, log_type, business_id, operate_type, operator_ucid, operator_name, operator_ip, operation_reason, created_time, brand, log_content FROM sh_housedel_log WHERE business_id = ? AND operate_type = ? AND operation_reason IN ( ? ) LIMIT ? 2018-02-26 14:11:05.775 DEBUG 14164 --- [28620-thread-21] c.l.m.q.d.H.selectCustom : ==&gt; Parameters: 101000000122(Long), u(String), house_maintain_update(String), 10(Integer)2018-02-26 14:11:05.783 DEBUG 14164 --- [28620-thread-21] c.l.m.q.d.H.selectCustom : &lt;== Total: 2 Druid 打印 SQL12018-02-26 14:18:02.100 DEBUG 14848 --- [28620-thread-12] druid.sql.Statement : &#123;conn-10001, pstmt-20001&#125; executed. SELECT id, log_type, business_id, operate_type, operator_ucid , operator_name, operator_ip, operation_reason, created_time, brand , log_content FROM sh_housedel_log WHERE business_id = 101000000122 AND operate_type = &apos;u&apos; AND operation_reason IN (&apos;house_maintain_update&apos;) LIMIT 10 问题分析开启 Druid 打印 SQL 的功能很简单，我会在文章的最后贴出来，但是在关闭 MyBatis 打印功能的时候却遇到了问题。 观察上述日志可以发现，MyBatis 打印时使用的 loggerName 是以当前项目的包名 com.lianjia.mls 作为前缀的（实际是 Mapper.xml 的 namespace），并不是 MyBatis 的包名 org.mybatis，而我需要在开启当前项目 DEBUG 日志的同时把 MyBatis 打印的 SQL 去掉，所以之前将 org.mybatis 的日志级别设为 INFO 的想法并不能生效。 而且由于 loggerName 的原因，对于打印日志的代码位置也毫无头绪，还好通过全局搜索 Preparing: 关键字定位到了 org.apache.ibatis.logging.jdbc.ConnectionLogger 类。 然后一路向上查找调用者。 最终发现该 Logger 是由 org.apache.ibatis.mapping.MappedStatement 类创建的，默认值为 mapperId，并且通过代码我们可以看到这里有个神奇的配置： logPrefix，它可以为 loggerName 增加前缀，也就是说，之前通过配置日志级别来禁止 MyBatis 打印 SQL 的想法是可行的，只需要将 logPrefix 的日志级别设为 INFO 即可。 大功告成至此该问题已完美解决，既保留了项目的 DEBUG 日志，同时又禁止了 MyBatis 的打印 SQL 功能，而且对 MyBatis 本身的日志配置也不影响，可谓一举三得。 打印 SQL 配置MyBatis 配置12345678# application.ymlmybatis: configuration: log-prefix: executableSql.logger: executableSql: debug Druid 配置123456789101112131415161718192021# application.ymllogger: druid.sql.Statement: debug## 以下功能由 [druid-spring-boot-starter](https://github.com/drtrang/druid-spring-boot) 提供spring: datasource: druid: slf4j: enabled: true statement-log-enabled: true statement-sql-format-option: upp-case: true pretty-format: false statement-create-after-log-enabled: false statement-parameter-set-log-enabled: false statement-executable-sql-log-enable: true statement-execute-after-log-enabled: false statement-parameter-clear-log-enable: false statement-close-after-log-enabled: false","categories":[{"name":"技术内幕","slug":"技术内幕","permalink":"http://blog.trang.space/categories/技术内幕/"}],"tags":[{"name":"druid","slug":"druid","permalink":"http://blog.trang.space/tags/druid/"},{"name":"mybatis","slug":"mybatis","permalink":"http://blog.trang.space/tags/mybatis/"}]},{"title":"Spring Boot 的 Maven 项目原型","slug":"Spring Boot 的 Maven 项目原型","date":"2017-08-10T16:00:00.000Z","updated":"2017-08-10T16:00:00.000Z","comments":true,"path":"2017/08/11/Spring Boot 的 Maven 项目原型/","link":"","permalink":"http://blog.trang.space/2017/08/11/Spring Boot 的 Maven 项目原型/","excerpt":"","text":"概要随着微服务的流行，Spring Boot 在广大开发者中占据了越来越重要的位置，其开箱即用、自动配置的特性也给我们带来了诸多便利。 然而 Spring Boot 只是一个基础框架，我们还是需要新建工程、技术选型、参数配置等一系列步骤才能搭建出一个完整的项目，繁冗又无趣，尤其对于初学者来说，这一过程还可能会出现各种各样莫名其妙的问题。 Spring Boot Archetype 则是为了解决上述痛点而打造，借助 maven-archetype-plugin 插件，预置了日志、缓存、AOP、数据访问、代码生成、文档生成等模块，并提供常见技术的最佳实践，用户只需几秒即可快速构建一个可运行的 Spring Boot 项目。 地址主页：https://github.com/drtrang/maven-archetype-springboot问题：https://github.com/drtrang/maven-archetype-springboot/issues后续计划：https://github.com/drtrang/maven-archetype-springboot/blob/master/TODO.md 特点 基于 Spring Boot 1.5.6，内嵌 Jetty 增加全局异常捕获、view to json 等功能 集成通用 Mapper 和 PageHelper，提供 BaseService，常用 CRUD 无需编写代码 集成 MyBatis Generator，提供 MBG Plugin Extension，如自动生成 Service 插件、支持 Lombok 插件等等 集成 Druid Spring Boot Starter，无需显式声明数据源（支持多数据源） 集成 Swagger2，HTTP 接口自动生成接口文档 提供常用工具，如 SpringContextHolder、SqlMapper ISSUE项目刚刚发布，许多方面还有不足，希望大家多提意见，如果有任何想法和讨论，都可以放到 ISSUE 平台，我会及时回复。有条件的用户还可以提 PR，成为该项目的 Contributor。 About MeQQ：349096849Email：donghao.l@hotmail.comBlog：Trang’s Blog","categories":[{"name":"最佳实践","slug":"最佳实践","permalink":"http://blog.trang.space/categories/最佳实践/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blog.trang.space/tags/Spring-Boot/"}]},{"title":"Druid Spring Boot Starter","slug":"Druid Spring Boot Starter","date":"2017-07-12T16:00:00.000Z","updated":"2017-07-12T16:00:00.000Z","comments":true,"path":"2017/07/13/Druid Spring Boot Starter/","link":"","permalink":"http://blog.trang.space/2017/07/13/Druid Spring Boot Starter/","excerpt":"","text":"依赖12345&lt;dependency&gt; &lt;groupId&gt;com.github.drtrang&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt;&lt;/dependency&gt; NEW ! 新增 ConfigFilter 的自动配置，替换 Druid 默认的 connectionProperties 方式 完美支持多数据源 ISSUE #2 配置简单配置在引入依赖的情况下，只需如下配置即可使用 Druid： 123456spring: datasource: driver-class-name: org.h2.Driver url: jdbc:h2:file:./samples username: root password: 123456 Druid 连接池Druid Spring Boot Starter 会将以 spring.datasource.druid 为前缀的配置注入到 DruidDataSource，且 DruidDataSource 中的所有参数均可自定义。 12345678910111213spring: datasource: druid: initial-size: 1 min-idle: 1 max-active: 10 validation-query: SELECT 1 test-while-idle: true test-on-borrow: false test-on-return: false pool-prepared-statements: true max-open-prepared-statements: 20 use-global-data-source-stat: true Druid 高级特性Druid Spring Boot Starter 添加了 Druid 的大部分特性，如 StatFilter、WallFilter、ConfigFilter、WebStatFilter 等，其中 StatFilter 默认打开，其它特性默认关闭，需要手动开启。 同样，每个特性的参数均可自定义，具体配置可以用 IDE 的自动提示功能或者阅读 Druid 的 Wiki 查看。 123456789101112131415161718192021222324spring: datasource: druid: slf4j: # 开启 Slf4jFilter enabled: true wall: # 开启 WallFilter enabled: true config: ## WallConfig 配置 select-all-column-allow: false config: # 开启 ConfigFilter enabled: true web-stat: # 开启 Web 监控 enabled: true aop-stat: # 开启 Aop 监控 enabled: true stat-view-servlet: # 开启监控页面 enabled: true 多数据源1.0.2 版本新增多数据源支持，使用方式请查看 DruidMultiDataSource.md。 配置示例application.yml 自动提示Druid Spring Boot Starter 基于 spring-boot-configuration-processor 模块，支持 IDE 的自动提示。 该功能会持续优化，致力打造最方便、最友好的 Starter。 自定义参数： 参数说明： 参数枚举值： 演示druid-spring-boot-samples 演示了 Starter 的使用方式，可以作为参考。 Change LogRelease Notes TODO任何意见和建议可以提 ISSUE，我会酌情加到 Todo List，一般情况一周内迭代完毕。 About MeQQ：349096849Email：donghao.l@hotmail.comBlog：Trang’s Blog","categories":[{"name":"最佳实践","slug":"最佳实践","permalink":"http://blog.trang.space/categories/最佳实践/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"http://blog.trang.space/tags/spring-boot/"},{"name":"java","slug":"java","permalink":"http://blog.trang.space/tags/java/"}]},{"title":"MyBatis Type Handlers for Encrypt","slug":"MyBatis Type Handlers for Encrypt","date":"2017-04-16T16:00:00.000Z","updated":"2017-05-22T16:00:00.000Z","comments":true,"path":"2017/04/17/MyBatis Type Handlers for Encrypt/","link":"","permalink":"http://blog.trang.space/2017/04/17/MyBatis Type Handlers for Encrypt/","excerpt":"","text":"背景应公司安全部门要求，需要对数据库中的敏感信息做加密处理。由于此次需求涉及的字段较多，手动加解密颇为不便且改动较大，一个更加简单、通用的解决方案势在必行。 typehandlers-encrypt 项目在这种背景下诞生，用户使用时无需更改业务代码，仅需少量配置即可实现数据库指定字段的加解密操作，大大减小了对用户的影响。 实现原理typehandlers-encrypt 基于 MyBatis 的 TypeHandler 开发，通过 TypeHandler 可以在 JavaType 和 JdbcType 中互相转换的特性，拦截 JavaType 为 com.github.trang.typehandlers.alias.Encrypt 的 SQL，在预处理语句（PreparedStatement）中设置参数时自动加密，并在结果集（ResultSet）中取值时自动解密。 注：由于依赖 MyBatis，使用时需要将 EncryptTypeHandler 和 Encrypt 注册到 MyBatis，否则无法生效，注册方式见 声明 EncryptTypeHandler。 应用依赖12345&lt;dependency&gt; &lt;groupId&gt;com.github.drtrang&lt;/groupId&gt; &lt;artifactId&gt;typehandlers-encrypt&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; 声明 EncryptTypeHandler1. 单独使用 MyBatis12345678&lt;!-- mybatis-config.xml --&gt;&lt;typeAliases&gt; &lt;package name=\"com.github.trang.typehandlers.alias\" /&gt;&lt;/typeAliases&gt;&lt;typeHandlers&gt; &lt;package name=\"com.github.trang.typehandlers.type\" /&gt;&lt;/typeHandlers&gt; 2. 与 Spring 结合1234567@Beanpublic SqlSessionFactory sqlSessionFactory(Configuration config) &#123; SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setTypeAliasesPackage(\"com.github.trang.typehandlers.alias\"); factory.setTypeHandlersPackage(\"com.github.trang.typehandlers.type\"); return factory.getObject();&#125; 3. 与 SpringBoot 结合1234##application.ymlmybatis: type-aliases-package: com.github.trang.typehandlers.alias type-handlers-package: com.github.trang.typehandlers.type 注：以上配置方式任选其一即可，请根据实际情况选择。 使用 EncryptTypeHandler1234567891011121314151617&lt;!-- select --&gt;&lt;resultMap id=\"BaseResultMap\" type=\"user\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\" /&gt; &lt;result column=\"username\" javaType=\"string\" jdbcType=\"VARCHAR\" property=\"username\" /&gt; &lt;result column=\"password\" javaType=\"encrypt\" jdbcType=\"VARCHAR\" property=\"password\" /&gt;&lt;/resultMap&gt;&lt;!-- insert --&gt;&lt;insert id=\"insert\" parameterType=\"user\"&gt; insert into user (id, username, password) values (#&#123;id,jdbcType=BIGINT&#125;, #&#123;username,jdbcType=VARCHAR&#125;, #&#123;password, javaType=encrypt, jdbcType=VARCHAR&#125;)&lt;/insert&gt;&lt;!-- update --&gt;&lt;update id=\"update\" parameterType=\"user\"&gt; update user set password=#&#123;password, javaType=encrypt, jdbcType=VARCHAR&#125; where id=#&#123;id&#125;&lt;/update&gt; 进阶typehandlers-encrypt 内置了 16 位长度密钥与 AES 加密算法，支持开箱即用，但用户也可以自定义密钥和加密算法，只需要在配置文件中声明对应的属性即可。需要注意，两者同时配置时，要声明在同一文件里。 配置示例：12encrypt.private.key=xxxencrypt.class.name=com.github.trang.typehandlers.crypt.SimpleEncrypt 配置文件查找方式一：项目启动时，会在项目的 Classpath 中依次查找名称为 encrypt、properties/config-common、properties/config、config、application 的 Properties 文件，直到文件存在且文件中包含名称为 encrypt.private.key 的属性时停止。 方式二：如果项目中不存在以上文件，且不想单独新增，也可以在项目启动时调用 ConfigUtil.bundleNames(&quot;xxx&quot;) 来指定要读取的文件，这时只会从用户给定的文件中查找。 当没有查找到相应配置时，项目会使用内置的配置。 自定义密钥typehandlers-encrypt 支持自定义密钥，只需在配置文件中声明即可。1encrypt.private.key=xxx 自定义加密算法typehandlers-encrypt 默认的加密算法是 AES 对称加密，如果默认算法不满足实际需求，用户可以自己实现 com.github.trang.typehandlers.crypt.Crypt 接口，并在配置文件中声明实现类的全路径。1encrypt.class.name=com.github.trang.typehandlers.crypt.SimpleEncrypt 演示目前项目已开源，并上传到 Github，大家感兴趣的话可以阅读源码。Github 中有配套的 Demo 演示 typehandlers-encrypt-demo，其中包括 typehandlers-encrypt 完整的使用方式，可以作为参考。 About MeQQ：349096849Email：donghao.l@hotmail.comBlog：Trang’s Blog 注意： 目前 EncryptTypeHandler 只支持 JavaType 为 String 的情形，如有其它需求，请及时联系我。 加密时字段只过滤 null 值，非 null 的字段不做任何处理直接加密。","categories":[{"name":"最佳实践","slug":"最佳实践","permalink":"http://blog.trang.space/categories/最佳实践/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://blog.trang.space/tags/MyBatis/"}]},{"title":"应用层读写分离的改进","slug":"应用层读写分离的改进","date":"2017-04-16T16:00:00.000Z","updated":"2017-05-22T16:00:00.000Z","comments":true,"path":"2017/04/17/应用层读写分离的改进/","link":"","permalink":"http://blog.trang.space/2017/04/17/应用层读写分离的改进/","excerpt":"","text":"背景数据库读写分离是构建高性能 Web 架构不可缺少的一环，其主要提升在于： 主从职责单一，主写从读，可以极大程度地缓解 X 锁和 S 锁的竞争，并且可以进行针对性调优 请求分流，减少主库压力 当读成为 DB 瓶颈时，很容易进行水平拓展 增加冗余，实现高可用，出现故障后可快速恢复，仅丢失少量数据或不丢失数据 实现方式读写分离首先需要 DB 实例的支持，配置主库、从库以及主从同步策略，此步骤一般交给 OP 即可。实例搭建完毕后，我们就可以开发相应模块，以实现真正的读写分离。 业界的实现方式一般分为两种：DB 中间件 和 应用层读写分离，二者均有各自的优缺点，详情见下表： DB 中间件 优点：对于应用透明；不限语言缺点：专人部署 + 维护；保证 HA、LB；一般只支持 MySQL 应用层读写分离 优点：开发简单，团队内部可以自行消化；基于 JDBC 驱动或框架，理论支持任意类型的 DB缺点：通用性差，各应用需要自己实现；手动指定数据源 用不用 DB 中间件需要考虑实际情况，如数据体量和有没有人维护等等，本文讲的是应用层读写分离。 当前方案通过自定义注解 @DataSourceRoute，手动声明当前方法操作的数据源，再通过切面拦截该切入点，路由到目标数据源。 因为实际中还要与事务结合，所以又写了一套基于事务路由主从数据源的切面，使用起来较为繁琐。 1234567891011121314151617181920//annotationpublic @interface DataSourceRoute &#123; AccessType type() default AccessType.MASTER;&#125;//aspectpublic class DataSourceRouteAspect &#123; @Before(\"@annotation(DataSourceRoute)\") public void before(JoinPoint point) &#123; Method targetMethod = ((MethodSignature) point.getSignature()).getMethod(); DataSourceRoute annotation = targetMethod.getAnnotation(DataSourceRoute.class); DynamicDataSourceHolder.route(annotation.type()); &#125;&#125;//dao@DataSourceRoute(type=AccessType.SLAVE)public Housedel findByPK(Long housedelCode) &#123; return mapper.findByPK(housedelCode);&#125; 改进方案其实总结一下我们使用读写分离的场景会发现，主库一般负责写入（偶尔用来读），从库则全部用来读取。而为了保障数据的正确性，我们在写入操作时一般会加上事务（这也是我推荐的最佳实践），也就是说，大部分事务操作是在写入，大部分非事务操作则是在读取，由此可见读写分离和事务之间是有一定关联的。 既然思路是可行的，那我们不妨思考一下，实际使用中具体有哪些场景呢？ 序号 事务 数据源 操作 1 无 从库 读 2 无 主库 读 3 有 从库 读 4 有 主库 写 第 1 种，无事务从库读取。典型的只读场景，我们的业务场景一般是读多写少，为了方便，可以作为默认选项。 第 2 种，无事务主库读取。主库中读取数据的情况还是比较少见的，一般是因为对数据的实时性要求较高，而 MySQL 的主从复制是异步的，中间会有短暂的时间差，为了保证数据的一致性，会直接从主库读取。 第 3 种，有事务从库读取。前面我们说道，事务一般加在写入操作上，但也有个别情况只读时也需要加入事务，比如在当前只读事务内，不希望其它事务更改数据，从而保证数据前后的一致性。 第 4 种，有事务主库写入。典型的写入场景，数据写入主库后，异步复制到从库。 落地那么如何实现呢？阅读 Spring 的源码会发现，DataSourceTransactionManager 是 Spring 用来管理事务的类，我们只需要自定义一个事务管理器，在开启事务之前指定数据源即可。 有了之前的分析，我们可以得到以下规则：默认无事务时路由到从库，有事务且非只读时路由到主库。 定义动态数据源 123456789101112131415161718192021222324252627282930313233public class DynamicDataSource extends AbstractRoutingDataSource &#123; public DynamicDataSource(Object defaultTargetDataSource, Map&lt;Object, Object&gt; targetDataSources) &#123; super.setDefaultTargetDataSource(defaultTargetDataSource); super.setTargetDataSources(targetDataSources); &#125; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceHolder.get(); &#125;&#125;public final class DynamicDataSourceHolder &#123; public static final String MASTER_DATA_SOURCE = \"Master\"; public static final String SLAVE_DATA_SOURCE = \"Slave\"; private static final ThreadLocal&lt;String&gt; CONTAINER = ThreadLocal.withInitial( () -&gt; DynamicDataSourceHolder.SLAVE_DATA_SOURCE ); public static void routeMaster() &#123; CONTAINER.set(MASTER_DATA_SOURCE); &#125; public static void routeSlave() &#123; CONTAINER.set(SLAVE_DATA_SOURCE); &#125; public static String get() &#123; return CONTAINER.get(); &#125; public static void clear() &#123; CONTAINER.remove(); &#125;&#125; 声明动态数据源 1234567891011121314151617181920212223@Configurationpublic class SpringDataSourceConfig &#123; @Bean(initMethod = \"init\", destroyMethod = \"close\") public DruidDataSource masterDataSource() &#123; return new DruidDataSource(); &#125; @Bean(initMethod = \"init\", destroyMethod = \"close\") public DruidDataSource slaveDataSource() &#123; return new DruidDataSource(); &#125; @Bean @Primary public DynamicDataSource dataSource(DruidDataSource masterDataSource, DruidDataSource slaveDataSource) &#123; Map&lt;Object, Object&gt; targetDataSources = ImmutableMap.builder() .put(MASTER_DATA_SOURCE, masterDataSource) .put(SLAVE_DATA_SOURCE, slaveDataSource) .build(); return new DynamicDataSource(slaveDataSource, targetDataSources); &#125;&#125; 重写 Spring 默认的事务管理器 1234567891011121314151617181920public class DynamicDataSourceTransactionManager extends DataSourceTransactionManager &#123; public DynamicDataSourceTransactionManager(DataSource dataSource) &#123; super(dataSource); &#125; @Override protected void doBegin(Object transaction, TransactionDefinition definition) &#123; if (!definition.isReadOnly()) &#123; DynamicDataSourceHolder.routeMaster(); &#125; super.doBegin(transaction, definition); &#125; @Override protected void doCleanupAfterCompletion(Object transaction) &#123; DynamicDataSourceHolder.clear(); super.doCleanupAfterCompletion(transaction); &#125;&#125; 声明自定义的事务管理器 123456789101112@Configuration@EnableTransactionManagement(proxyTargetClass = true)public class SpringDaoConfig implements TransactionManagementConfigurer &#123; @Autowired private DynamicDataSource dataSource; @Override @Bean public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return new DynamicDataSourceTransactionManager(dataSource); &#125;&#125; 代码贴完了，让我们来看看能不能满足之前的 4 种场景呢？ 其中 1、4 的区别仅仅是加不加事务，比较简单，那么待解决的还有 2 和 3。第 2 种因为没有事务，需要我们手动指定数据源，第 3 种则使用 Spring 提供的只读事务即可实现。 序号 事务 数据源 操作 实现方式 1 无 从库 读 默认 2 无 主库 读 手动指定 DynamicDataSourceHolder.routeMaster() 3 有 从库 读 @Transactional(readOnly = true) 4 有 主库 写 @Transactional 如此一来，之前的问题都已经解决。我们仅仅通过 Spring 自带的 @Transactional 注解即可指定数据源，对比之前简化不少。 演示由于篇幅原因，文章中没有展示具体的执行结果。完整代码已打包成 dynamic-data-source-demo项目，并上传到 Github，项目中提供完整的单元测试，详情大家可以 Clone 到本地自己执行一遍。 dynamic-data-source-demo 项目基于 Spring Boot，集成了 MyBatis、通用 Mapper、PageHelper、Druid、Copiers，可以作为简单的脚手架使用，欢迎大家 Star 或者 Fork 到自己的仓库。 About MeQQ：349096849Email：donghao.l@hotmail.comBlog：Trang’s Blog","categories":[{"name":"最佳实践","slug":"最佳实践","permalink":"http://blog.trang.space/categories/最佳实践/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://blog.trang.space/tags/架构/"}]},{"title":"Copiers","slug":"Copiers","date":"2017-03-20T16:00:00.000Z","updated":"2018-04-08T16:00:00.000Z","comments":true,"path":"2017/03/21/Copiers/","link":"","permalink":"http://blog.trang.space/2017/03/21/Copiers/","excerpt":"","text":"Copiers 是一个优雅的 Bean 拷贝工具，可通过友好的 Fluent API 帮助用户完成拷贝对象的操作。 依赖12345678910111213&lt;!-- java7 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.drtrang&lt;/groupId&gt; &lt;artifactId&gt;copiers&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- java8 or higher --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.drtrang&lt;/groupId&gt; &lt;artifactId&gt;copiers&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt;&lt;/dependency&gt; 底层实现Copiers 目前有两种实现：Cglib &amp; Orika，用户可以通过工厂方法来切换底层的拷贝方式。 123456// orikaCopiers.create(Class&lt;F&gt; sourceClass, Class&lt;T&gt; targetClass)Copiers.createOrika(Class&lt;F&gt; sourceClass, Class&lt;T&gt; targetClass)// cglibCopiers.createCglib(Class&lt;F&gt; sourceClass, Class&lt;T&gt; targetClass)Copiers.createCglib(Class&lt;F&gt; sourceClass, Class&lt;T&gt; targetClass, Converter converter) CglibCglib 中的 BeanCopier 是目前性能最好的拷贝方式，基于 ASM 字节码增强技术，千万次拷贝仅需毫秒即可完成，但高性能带来的显著缺点是功能单一、拓展性差，BeanCopier 仅支持源对象到目标对象的完全拷贝，不支持自定义映射，Convert 拓展也只能对拷贝的 value 做处理，很多情况下不满足实际的业务需求。 注意： BeanCopier 只拷贝名称和类型都相同的属性 当目标类的 setter 方法少于 getter 方法时，会导致创建 BeanCopier 失败 一旦使用 Converter，BeanCopier 将完全使用 Converter 中定义的规则去拷贝，所以在 convert() 方法中要考虑到所有的属性，否则会抛出 ClassCastException OrikaOrika 基于 Javassist 字节码技术，千万次拷贝在 5s 左右。性能虽不如 Cglib，但 Orika 的优点在于灵活性、扩展性强，详细介绍可以查看 Orika 的 Github：https://github.com/orika-mapper/orika，另外强烈推荐这篇使用教程：http://www.baeldung.com/orika-mapping 注意： 拷贝结果为浅拷贝 支持级联拷贝，但是需要提前注册好级联对象之间的映射关系，且可以使用 parent() 方法来指定父类 支持源对象中的集合类型直接拷贝到目标对象的集合 不同类型有默认的 Converter 做转换 使用方式通过工厂方法建立 sourceClass 与 targetClass 之间的关系后，调用 copy() 方法即可完成 Bean 拷贝，调用 map() 方法即可完成 List 拷贝，简洁高效。 Cglib1234567891011121314151617// 建立 User.class 与 UserEntity.class 之间的映射关系Copier copier = Copiers.createCglib(User.class, UserEntity.class);// 拷贝对象，创建新对象User user = User.of(\"trang\", 25);UserEntity entity = copier.copy(user);// 拷贝对象，传入已有对象，完全拷贝User user = User.of(\"trang\", null);UserEntity entity = UserEntity.of(\"meng\", 24);copier.copy(user, entity);// 拷贝 List，创建新 ListUser trang = User.of(\"trang\", 25);User meng = User.of(\"meng\", 24);List&lt;User&gt; family = ImmutableList.of(trang, meng);List&lt;UserEntity&gt; entries = copier.map(family); Orika1234567891011121314151617// 建立 User.class 与 UserEntity.class 之间的映射关系Copier copier = Copiers.create(User.class, UserEntity.class);// 拷贝对象，创建新对象User user = User.of(\"trang\", 25);UserEntity entity = copier.copy(user);// 拷贝对象，传入已有对象，不会拷贝值为 null 的属性（可以配置）User user = User.of(\"trang\", null);UserEntity entity = UserEntity.of(\"meng\", 24);copier.copy(user, entity);// 拷贝 List，创建新 ListUser trang = User.of(\"trang\", 25);User meng = User.of(\"meng\", 24);List&lt;User&gt; family = ImmutableList.of(trang, meng);List&lt;UserEntity&gt; entries = copier.map(family); Orika 进阶Orika 支持强大的自定义关系映射，并且使用缓存技术，一次注册后续直接使用。 1234567891011121314151617181920212223242526// 跳过拷贝的属性，支持配置多个// Orika 默认使用全参构造，这时 skip() 不生效，需要使用不包含 skip 属性的构造方法，// 所以 Copiers 将默认值改为了无参构造，用户也可以在调用 skip() 后使用 constructor() 方法自己指定Copier&lt;User, UserEntity&gt; copier = Copiers.createOrika(User.class, UserEntity.class) .skip(\"age\", \"sex\") .register();// 将源对象的 `name` 属性映射到目标对象的 `username` 属性Copier&lt;User, UserEntity&gt; copier = Copiers.createOrika(User.class, UserEntity.class) .field(\"name\", \"username\") .register();// 开启拷贝 null 值，默认 Orika 不会将源对象中值为 null 的属性拷贝到目标对象中，如有需要可以手动开启Copier&lt;User, UserEntity&gt; copier = Copiers.createOrika(User.class, UserEntity.class) .nulls() .register();// 全局自定义映射关系，若和其它方法结合使用则在最后执行Copier&lt;User, UserEntity&gt; copier = Copiers.createOrika(User.class, UserEntity.class) .customize(new CustomMapper&lt;User, UserEntity&gt;() &#123; @Override public void mapAtoB(User source, UserEntity target, MappingContext context) &#123; target.setUsername(\"prefix:\" + source.getName()); &#125; &#125;) .register(); 当然，以上映射关系可以任意搭配使用，同样只需一次注册。 1234567891011121314// 创建 copierCopier&lt;User, UserEntity&gt; copier = Copiers.createOrika(User.class, UserEntity.class) // 跳过拷贝 .skip(\"age\", \"sex\") // 自定义属性映射 .field(\"name\", \"username\") // 全局自定义映射关系 .customize(new CustomMapper&lt;User, UserEntity&gt;() &#123; @Override public void mapAtoB(User source, UserEntity target, MappingContext context) &#123; target.setUsername(\"prefix:\" + source.getName()); &#125; &#125;) .register(); 如果你在使用 Java8 那就更好了，利用 Copiers 可以更容易的完成拷贝操作。 12345678910111213// 创建 copierCopier&lt;User, UserEntity&gt; copier = Copiers.createOrika(User.class, UserEntity.class) .field(\"name\", \"username\") .register();// 使用 Stream 拷贝 ListsourceList.stream().map(copier::copy).collect(toList()); //copier.map(sourceList);// 使用并行 Stream 拷贝 ListsourceList.parallelStream().map(copier::copy).collect(toList());// 使用 Optional 拷贝 ListOptional.of(name) .map(service::selectByName) .map(copier::map) .orElse(emptyList()); Change LogRelease Notes TODO任何意见和建议可以提 ISSUE，我会酌情加到 TODO List，一般情况一周内迭代完毕。 About MeQQ：349096849Email：donghao.l@hotmail.comBlog：Trang’s Blog","categories":[{"name":"工具控","slug":"工具控","permalink":"http://blog.trang.space/categories/工具控/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.trang.space/tags/java/"},{"name":"tools","slug":"tools","permalink":"http://blog.trang.space/tags/tools/"}]},{"title":"Guava 学习手册","slug":"Guava 学习手册","date":"2016-07-20T16:00:00.000Z","updated":"2016-07-20T16:00:00.000Z","comments":true,"path":"2016/07/21/Guava 学习手册/","link":"","permalink":"http://blog.trang.space/2016/07/21/Guava 学习手册/","excerpt":"","text":"com.google.common.base字符串处理Guava 把字符串处理动作分了几大类，每种动作都有对应的工具类实现，我们可以根据需要使用对应的工具类。 CharMatchercom.google.common.base.CharMatcher 是 Guava 提供的用于进行字符匹配的工具类，翻开 CharMatcher 的源码，我们知道 CharMatcher 是一个抽象类，在其内部 Guava 做了大量默认实现，用来更方便的对字符串做匹配，并通过构造者模式对匹配后的字符串进行处理。 Note：不支持正则表达式。 Joinercom.google.common.base.Joiner 用来拼接字符串，可以避免大量的手动拼接 appendTo() 方法，Joiner 可以实现 Iterable&lt;?&gt;、Object[]、Map&lt;?, ?&gt; 类型的拼接。但要实现基本类型数组的拼接就无能为力了，这时就需要借助 com.google.common.base.primitives 包的基本类型工具类来实现了。 Joiner 底层通过 StringBuilder 实现，非线程安全。 Splittercom.google.common.base.Splitter 用来分割字符串，可以方便的以任意字符分割字符串，并提供转换为 Map 的方法 MapSplitter.withKeyValueSeparator(String separator)。 Note：支持正则表达式分割字符串。 Stringscom.google.common.base.Strings 的功能较少，Guava 提供的其它几个工具类已基本可以实现字符串处理的相关功能。 Charsets字符串编码一直是我们很头疼的事情，相信我们都写过这样一行代码： 12String s = \"trang\";byte[] bytes = s.getBytes(Charset.forName(\"UTF\")); 这样写有很多缺点，首先我们的大脑得记住常用的字符串编码，不是 UTF_，不是 UTF+，只能是 UTF- 或者 UTF，其次错误输入后的后果也很严重，JVM 会抛出 java.nio.charset.UnsupportedCharsetException 异常。 com.google.common.base.Charsets 给我们提供了一种便利的方式，Charsets 类提供了常见的 Charset 编码集，给我们的大脑腾出了位置并且避免了异常。 Note：Java中提供了类似功能的 java.nio.charset.StandardCharsets类。 CaseFormatcom.google.common.base.CaseFormat 很机智的替我们解决的大小写转换的问题，并且提供了额外的内容。 在处理数据库与 POJO 的映射时，该类有奇效。 类型 说明 示例 LOWER_CAMEL 小写驼峰 lowerCamel LOWER_HYPHEN 小写连接符 lower-hyphen LOWER_UNDERSCORE 小写下划线 lower_underscore UPPER_CAMEL 大写驼峰 UpperCamel UPPER_UNDERSCORE 大写下划线 UPPER_UNDERSCORE 函数式编程在 Java8 面世之前，Guava 一直是函数式编程的不二之选，但过度使用 Guava 函数式编程会导致冗长、混乱、可读性差而且低效的代码。这是迄今为止最容易（也是最经常）被滥用的部分，如果你想通过函数式风格达成一行代码，致使这行代码长到荒唐，Guava 团队会泪流满面。 Predicate 和 Function 是函数式编程中最重要的两个接口，通常通过匿名内部类的方式实现自己的函数，也可以通过对应的工具类使用 Guava 已为你写好的函数。 Predicatecom.google.common.base.Predicate&lt;T&gt;，断言预期结果，如果与预期不符则放弃。Predicate 只声明了一个方法 boolean apply(T input) ，使用时只需要实现断言表达式即可。 CharMatcher 和 Range 也是通过 Predicate 实现的。 常见使用 Predicate 的方法： 12345678Iterables.filter(Iterable&lt;T&gt; unfiltered, Predicate&lt;? super T&gt; predicate)FluentIterable.filter(Predicate&lt;? super T&gt; predicate)Collections.filter(Collection&lt;E&gt; unfiltered, Predicate&lt;? super E&gt; predicate)Sets.filter(Set&lt;T&gt;, Predicate&lt;? super T&gt;)Maps.filterKeys(Map&lt;K, V&gt; unfiltered, Predicate&lt;? super K&gt; keyPredicate)Maps.filterValues(Map&lt;K, V&gt; unfiltered, Predicate&lt;? super V&gt; valuePredicate)Maps.filterEntries(Map&lt;K, V&gt; unfiltered, Predicate&lt;? super Entry&lt;K, V&gt;&gt; entryPredicate)Multimaps.filter(Predicate&lt;? super E&gt; predicate) Functioncom.google.common.base.Function&lt;F, T&gt;，函数，Function 最常用的功能是转换集合，同样只需要实现 T apply(F input) 即可愉快的玩耍了。 常见使用 Function 的方法： 1与`Predicate`基本一致 Suppliercom.google.common.base.Supplier&lt;T&gt; 可以对传入的对象进行包装构建后再输出。与前两个函数接口一样，Supplier 只提供了一个供实现的方法 T get()，用于获取包装后的对象。由于 Supplier 在对象的外层，所以 Supplier 的一个重要作用是赋予对象懒加载的特性。 其它工具类OptionalGuava 用 com.google.common.base.Optional 表示可能为null的T类型引用。一个 Optional 实例可能包含非 null 的引用（我们称之为引用存在），也可能什么也不包括（称之为引用缺失）。它从不说包含的是 null 值，而是用存在或缺失来表示。但 Optional 从不会包含 null 值引用。 Optional 最大的优点在于它是一种傻瓜式的防护。Optional 迫使你积极思考引用缺失的情况，因为你必须显式地从 Optional 获取引用。 Stopwatchcom.google.common.base.Stopwatch是一种灵活的代替System.currentTimeMillis()和System.nanoTime()的方式。 你可以把Stopwatch想象成一个秒表，它支持暂停和重置，并且支持java.util.concurrent.TimeUnit的任何计时单位。 com.google.common.collect拓展集合Guava对Java默认的集合做了大量拓展，以实现不同的业务需求。 ImmutabelMapGuava的Immutable系列被很多人推崇，Immutable对象的数据在创建时提供，并且在整个生命周期内不可变，这样带来了一些好处： 线程安全 节省空间，有效利用内存 可当做常量使用 以前我们常使用Collections.unmodifiableXxx()来定义常量集合，但我们都知道它是有缺陷的。以后当我们使用常量集合时，推荐大家使用Guava的Immutable集合，Guava把所有集合类都建立了对应的不可变集合。 常见ImmutabelMap实现类： 可变集合类型 来源 Guava不可变集合 Collection JDK ImmutableCollection List JDK ImmutableList Set JDK ImmutableSet SortedSet JDK ImmutableSortedSet Map JDK ImmutableMap SortedMap JDK ImmutableSortedMap Multiset Guava ImmutableMultiset SortedMultiset Guava ImmutableSortedMultiset Multimap Guava ImmutableMultimap ListMultimap Guava ImmutableListMultimap SetMultimap Guava ImmutableSetMultimap BiMap Guava ImmutableBiMap ClassToInstanceMap Guava ImmutableClassToInstanceMap TypeToInstanceMap Guava ImmutableTypeToInstanceMap Table Guava ImmutableTable RangeSet Guava ImmutableRangeSet RangeMap Guava ImmutableRangeMap Note：当进行add、remove等操作时抛出java.lang.UnsupportedOperationException，该异常为运行时异常，并不会在编译时提醒你，需要开发时注意所有ImmutableMap均不支持null值所有ImmutableMap均不支持插入相同的key MultiSetcom.google.common.collect.Multiset&lt;E&gt;和Set的区别是可以保存多个相同的对象。在JDK中，List和Set有一个基本的区别，就是List有序且可重复，而Set不能有重复，也不保证顺序（有些实现有顺序，例如LinkedHashSet和SortedSet等）所以Multiset占据了List和Set之间的一个灰色地带：允许重复，但不保证顺序。 常见使用场景：Multiset有一个有用的功能，就是跟踪每种对象的数量，所以你可以用来进行数字统计。1HashMultiset.&lt;Integer&gt;create().count(element); 常见MultiSet实现类： Value类型 来源 Gauva Multimap Enum JDK EnumMultiset HashMap JDK HashSetMultiset LinkedHashMap JDK LinkedHashMultiset TreeMap JDK TreeMultiset ConcurrentHashMap JDK ConcurrentHashMultiset ImmutableMap Guava ImmutableMultiset MultiMapGuava中提供了形如Map&lt;K, List&lt;V&gt;&gt;或者Map&lt;K, Set&lt;V&gt;&gt;的新集合com.google.common.collect.Multimap&lt;K, V&gt;，方便的实现了把一个键对应到多个值的数据结构。 常见MultiMap实现类： Value类型 来源 Gauva Multimap ArrayList JDK ArrayListMultimap LinkedList JDK LinkedListMultimap HashSet JDK HashMultimap LinkedHashSet JDK LinkedHashMultimap TreeSet JDK TreeMultimap ImmutableList Guava ImmutableListMultimap ImmutableSet Guava ImmutableSetMultimap Note：MultiMap并不是Map除了两个ImmutableMap，其它均支持null键和null值 BiMapcom.google.common.collect.BiMap&lt;K, V&gt;是一个双向Map，在BiMap中，键值都是唯一的。 常见BiMap实现类： Value类型 来源 Gauva Multimap HashMap JDK HashBiMap EnumMap JDK EnumBiMap EnumMap JDK EnumHashBiMap ImmutableMap Guava ImmutableBiMap Tablecom.google.common.collect.Table&lt;R, C, V&gt;代替了形如Map&lt;FirstName, Map&lt;LastName, Person&gt;&gt;的集合，通过行和列来确定唯一的值。 常见Table实现类： Value类型 来源 Gauva Multimap HashMap JDK HashBasedTable TreeMap JDK TreeBasedTable ImmutableMap Guava ImmutableTable Guava ArrayTable ClassToInstanceMapcom.google.common.collect.ClassToInstanceMap&lt;B&gt;是一种特殊的Map：它的键是类型，而值是符合键所指类型的对象。 Guava提供了两种有用的ClassToInstanceMap实现：com.google.common.collect.MutableClassToInstanceMap和 com.google.common.collect.ImmutableClassToInstanceMap。 为了扩展Map接口，ClassToInstanceMap额外声明了两个方法：T getInstance(Class&lt;T&gt;) 和T putInstance(Class&lt;T&gt;, T)，从而避免强制类型转换，同时保证了类型安全。 123ClassToInstanceMap&lt;Object&gt; map = MutableClassToInstanceMap.create();map.putInstance(Integer.class, );map.putInstance(String.class, \"\"); Note：通常泛型为java.lang.Object Range1234@TODOcom.google.common.collect.Range&lt;C extends Comparable&gt;com.google.common.collect.RangeSet&lt;C extends Comparable&gt;com.google.common.collect.RangeMap&lt;K extends Comparable, V&gt; 集合工具类Guava对JDK内置和Guava拓展的集合均开发了工具类，分别为Collections、Iterables、Lists、Sets、Maps、Queues、Multisets、Multimaps、Tables，里面囊括了异常强大的静态工具方法。 Guava对拓展的具体集合实现类没有提供基于工具类的初始化方法，而是直接在集合类中提供了静态工厂方法。 Collectionscom.google.common.collect.Collections提供的方法不多，最常用的方法是函数编程的两个方法，具体内容在 函数式编程： 12Collection&lt;E&gt; filter(Collection&lt;E&gt; unfiltered, Predicate&lt;? super E&gt; predicate)Collection&lt;T&gt; transform(Collection&lt;F&gt; fromCollection, Function&lt;? super F, T&gt; function) Iterablescom.google.common.collect.Iterables为所有实现java.lang.Iterable&lt;T&gt;接口的类提供了大量实用方法。如果你使用了Iterator，Guava同样为你提供了Iterators，它们的作用基本一致。 Iterables并不会傻瓜式的任何方法都会遍历对象，而是很精明的通过instanceof判断对象实际的类型，如果匹配上则调用该类型的方法，匹配不上才会遍历。 Note：建议用Iterables代替Collections Listscom.google.common.collect.Lists提供了创建List的工厂方法，其余有用的有两个： 12List&lt;List&lt;B&gt;&gt; cartesianProduct(List&lt;? extends List&lt;? extends B&gt;&gt; lists)List&lt;T&gt; reverse(List&lt;T&gt; list) Lists没有函数编程的filter()方法，需要使用工厂方法代替实现：1Lists.newArrayList(Iterables.filter(from, Predicates.contains(Pattern.compile(&quot;[-]&quot;)))); Sets由于Set的不重复特性，我们常用Set实现一些算法，而com.google.common.collect.Sets贴合实际的满足了我们的要求，提供了交集、并集、差集等多种运算方式，并定义了视图com.google.common.collect.Sets.SetView来展示结果。 1234SetView&lt;E&gt; intersection(final Set&lt;E&gt; set, final Set&lt;?&gt; set)SetView&lt;E&gt; union(final Set&lt;? extends E&gt; set, final Set&lt;? extends E&gt; set)SetView&lt;E&gt; difference(final Set&lt;E&gt; set, final Set&lt;?&gt; set)SetView&lt;E&gt; symmetricDifference(final Set&lt;? extends E&gt; set, final Set&lt;? extends E&gt; set) MultiSet的工具类为com.google.common.collect.MultiSet。 Mapscom.google.common.collect.Maps提供了Map、SortedMap、BiMap的工厂方法及工具，Multimap的工具类为com.google.common.collect.Multimaps。 Maps中比较常用的方法是ImmutableMap&lt;K, V&gt; uniqueIndex(Iterable&lt;V&gt; values, Function&lt;? super V, K&gt; keyFunction)。 比较器ComparisonChain在Java中，我们实现排序往往有两种方式： 要排序的对象实现`java.lang.Comparable&lt;T&gt;`接口，重写`compareTo(T o)`方法 定义排序对象，实现`java.util.Comparator&lt;T&gt;`接口，重写`compare(T o, T o)`方法 重写比较方法是件麻烦的事情，Guava又一次帮我们逃离苦海，利用com.google.common.collect.ComparisonChain轻松愉快的完成比较方法。12345678public int compare(Cut cut, Cut cut) &#123; // 按照Rorate -&gt; X -&gt; Y 排序 return ComparisonChain.start() .compare(cut.getRotate(), cut.getRotate()) .compare(cut.getX(), cut.getX()) .compare(cut.getY(), cut.getY()) .result();&#125; OrderingComparisonChain带来的功能仍然比较单一，而Guava同时为我们提供了异常强大且方便的链式调用比较器com.google.common.collect.Ordering&lt;T&gt;，Ordering实现了Comparator接口，所以完全可以用Ordering替代Comparator。 Ordering提供了大量的默认实现，每个比较器都提供了常见的链式调用方法，大家可以根据实际情况创建自己的比较器。 Note：基本类型的比较可以使用com.google.common.base.primitives包Java中提供了类似功能的java.util.Comparators类 com.google.common.cache缓存是一个成熟的系统中必不可少的一环，合理利用缓存可以显著提升系统响应速度，减少I/O压力，Java常见的缓存有Redis、Memcached、EhCache等，而今天我们介绍的是Guava提供的本地缓存Guava Cache。 Guava Cache在很多场景下都是相当有用的，比如初始化查找树，我们只需要对不同的树初始化一次，以后直接调用即可。 Guava Cache与ConcurrentMap很相似，但不完全一样。最基本的区别是ConcurrentMap会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache为了限制内存占用，通常都设定为自动回收元素。 应用缓存Cachecom.google.common.cache.Cache&lt;K, V&gt;是Guava Cache的基本接口，Guava为我们提供了一个默认实现LocalManualCache，我们可以通过CacheBuilder工具类的工厂方法来创建LocalManualCache对象。 1CacheBuilder.newBuilder().build() CacheLoader在使用Guava Cache前，首先问自己一个问题：有没有合理的默认方法来加载与键关联的值？如果没有，Cache就是为你打造的，你需要在获取缓存的值时传入一个Callable实例来保证Guava Cache的作用。如果有，那么CacheLoader更适合你，而这也是今天的重点。 com.google.common.cache.LoadingCache&lt;K, V&gt;是实现了CacheLoader的Guava Cache，与创建Cache实例时仅有一点不同，只需要调用build()的重载方法即可。 1CacheBuilder.newBuilder().build(cacheLoader); 正因为LoadingCache有了默认的加载方法，所以只需要调用get(K key)即可得到值。 自定义缓存CacheBuilder从之前的代码中大家都看到了，Guava Cache的实例正是通过CacheBuilder创建的，事实上，CacheBuilder的作用远远不止这些，掌握好CacheBuilder，享受自定义Guava Cache的乐趣吧。 自定义CacheBuilder参数： 方法 参数 说明 initialCapacity int 初始化容量 maximumSize long 最大容量 weigher Weigher 权重函数 maximumWeight long 最大权重 concurrencyLevel int 并发级别 expireAfterAccess long, TimeUnit 上次访问给定时间后回收 expireAfterWrite long, TimeUnit 缓存写入给定时间后回收 refreshAfterWrite long, TimeUnit 缓存写入给定时间后更新 removalListener RemovalListener 移除监听器(同步) recordStats 统计状态 CacheBuilder提供了一系列的参数供我们个性化，主要是为了缓存的回收。CacheBuilder创建的实例并不会自动清理失效的缓存，而是在你进行读或写操作的时候顺带维护。这样做的原因在于，如果要自动地持续清理缓存，就必须有一个线程，这个线程会和用户操作竞争共享锁。 com.google.common.net常用类@Beta: HostAndPort HostSpecifier InetAddresses InternetDomainName MediaType PercentEscaper UrlEscapers @Release: HttpHeadersGuava中的com.google.common.net包目前提供的功能较少，而且大多类都标注了@Beta的注解，在Guava中标记@Beta表示这个类还不稳定，有可能在以后的版本中变化，或者去掉，所以不建议大量使用，这里也是只做简单的介绍。 HttpHeaders先介绍下唯一一个没有@Beta注解的类HttpHeaders，这个类中并没有实质的方法，只是定义了一些Http头名称的常量，通常如果需要我们会自己定义这些常量，如果你引用了Guava包，那么就不再建议我们自己定义这些头名称的常量了，直接用它定义的即可。 这里面应该有几乎所有的Http头名称，例如：X_FORWARDED_FOR，CONTENT_TYPE，ACCEPT等，用法也没有必要介绍了，直接引用常量就可以了。 HostAndPort有时候我们需要得到请求的ip，这时候通畅需要自己写方法解析url。而Guava给我们提供的HostAndPort类正是做这种事情的利器，可以从字符串中得到ip和port1HostAndPort.fromString(String hostPortString) 参考资料： Guava API 瓜娃系列 Guava官方文档 Guava教程","categories":[{"name":"技术内幕","slug":"技术内幕","permalink":"http://blog.trang.space/categories/技术内幕/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://blog.trang.space/tags/Tools/"}]}]}